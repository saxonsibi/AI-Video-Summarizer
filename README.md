# AI Video Summarizer

An AI-powered application for video summarization, chatbot interaction, and short video generation.

## ğŸš€ Features

- **Video Upload**: Upload videos for processing
- **Automatic Transcription**: Extract audio and transcribe using Faster-Whisper
- **AI Summarization**: Generate full, bullet-point, and short summaries using BART
- **RAG Chatbot**: Ask questions about video content in natural language
- **Short Video Generator**: Create 9:16 short videos from highlights
- **Progress Tracking**: Real-time progress updates

## ğŸ› ï¸ Tech Stack

### Backend
- **Django + Django Rest Framework**: API backend
- **Celery**: Background task processing
- **Redis**: Task queue broker
- **Faster-Whisper**: Speech-to-text
- **BART**: Text summarization
- **FAISS**: Vector similarity search
- **LangChain**: RAG pipeline
- **MoviePy**: Video editing

### Frontend
- **React 18**: UI framework
- **Vite**: Build tool
- **Tailwind CSS**: Styling
- **React Router**: Navigation
- **Axios**: HTTP client
- **React Player**: Video playback

## ğŸ“ Project Structure

```
AI Video Summarizer/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ ai_video_summarizer/   # Django project config
â”‚   â”œâ”€â”€ videos/                  # Video processing app
â”‚   â”‚   â”œâ”€â”€ models.py           # Database models
â”‚   â”‚   â”œâ”€â”€ views.py            # API views
â”‚   â”‚   â”œâ”€â”€ tasks.py            # Celery tasks
â”‚   â”‚   â””â”€â”€ utils.py            # Utility functions
â”‚   â”œâ”€â”€ chatbot/                 # RAG chatbot app
â”‚   â”‚   â”œâ”€â”€ rag_engine.py       # RAG implementation
â”‚   â”‚   â””â”€â”€ views.py            # Chatbot API
â”‚   â””â”€â”€ summarizer/             # Text summarization app
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/         # React components
â”‚   â”‚   â”œâ”€â”€ pages/             # Page components
â”‚   â”‚   â””â”€â”€ services/           # API services
â”‚   â””â”€â”€ package.json
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Node.js 18+
- FFmpeg (for video processing)
- Redis (for Celery)

### Backend Setup

1. Create virtual environment:
```bash
cd backend
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
.\venv\Scripts\activate  # Windows
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Configure environment:
```bash
cp .env.example .env
# Edit .env with your settings
```

4. Run migrations:
```bash
python manage.py migrate
```

5. Start Redis (required for Celery):
```bash
redis-server
```

6. Start Celery worker:
```bash
celery -A ai_video_summarizer worker -l info
```

7. Start Django server:
```bash
python manage.py runserver
```

### Frontend Setup

1. Install dependencies:
```bash
cd frontend
npm install
```

2. Start development server:
```bash
npm run dev
```

3. Open http://localhost:5173

## ğŸ“¡ API Endpoints

### Videos
- `POST /api/videos/upload/` - Upload video
- `GET /api/videos/` - List videos
- `GET /api/videos/{id}/` - Get video details
- `POST /api/videos/{id}/generate_transcript/` - Generate transcript
- `POST /api/videos/{id}/generate_summary/` - Generate summary
- `POST /api/videos/{id}/generate_short/` - Generate short video

### Chatbot
- `POST /api/chatbot/chat/` - Send message
- `GET /api/chatbot/chat/?video_id=xxx` - Get suggested questions

## ğŸ¯ Usage

1. **Upload a video** from the homepage
2. **Wait for processing** - transcription and summarization happen automatically
3. **View summaries** in the Summaries tab
4. **Ask questions** in the Chatbot tab
5. **Generate shorts** in the Generate Short tab

## ğŸ”§ Configuration

### Whisper Model Size
Choose model size based on your hardware:
- `tiny` - Fastest, lowest accuracy
- `small` - Good balance
- `medium` - Better accuracy, slower
- `large` - Best accuracy, slowest

### Celery Workers
Scale workers for faster processing:
```bash
celery -A ai_video_summarizer worker -l info -c 4
```

## ğŸ“ License

MIT License

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch
3. Commit changes
4. Push to branch
5. Open Pull Request
